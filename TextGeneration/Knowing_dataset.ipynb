{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "path = './poetry1.txt.gz' # we just use one of the four datasets\n",
    "text = gzip.open(path, 'rt').read().lower().replace('\\ufeff', ' ') # now we get the poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 162595\n"
     ]
    }
   ],
   "source": [
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 40\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars)) # you can print indices_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 81248\n"
     ]
    }
   ],
   "source": [
    "maxlen = 100\n",
    "step = 2\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])  # print it\n",
    "    next_chars.append(text[i + maxlen]) # print it and then you'll know the goal of the experience\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Vectorizes the sequences with one hot encoding\n",
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1  \n",
    "## Now we get our input and label for RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "RNN = LSTM  # GRU\n",
    "lsize = 512\n",
    "nlayers = 2\n",
    "dropout = 0\n",
    "impl = 2\n",
    "\n",
    "model = Sequential()\n",
    "if nlayers == 1:\n",
    "    model.add(RNN(lsize, input_shape=(maxlen, len(chars)), implementation=impl, recurrent_dropout=dropout))\n",
    "else:\n",
    "    model.add(\n",
    "        RNN(lsize, input_shape=(maxlen, len(chars)), implementation=impl, recurrent_dropout=dropout, return_sequences=True))\n",
    "    for i in range(1, nlayers - 1):\n",
    "        model.add(RNN(lsize, implementation=impl, recurrent_dropout=dropout, return_sequences=True))\n",
    "    model.add(RNN(lsize, implementation=impl, recurrent_dropout=dropout))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = RMSprop(lr=0.01)\n",
    "#optimizer = SGD(lr=0.05, momentum=0.95)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
    "\n",
    "bsize = 2048\n",
    "iterations = 15\n",
    "epoch_it = 10\n",
    "\n",
    "# File for saving the generated text each iteration\n",
    "gfile = open('tgenerated-F%s-ML%d-S%d-NL%d-D%3.2f-BS%d.txt' % (path.split('.')[0], maxlen, lsize, nlayers, dropout, bsize), 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"\n",
    "    helper function to sample an index from a probability array\n",
    "\n",
    "    :param preds:\n",
    "    :param temperature:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed, numlines, gfile, wseed=False):\n",
    "    \"\"\"\n",
    "    Generates a number of lines (or at most 1000 characters) using the given seed\n",
    "    :param seed:\n",
    "    :param lines:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    generated = ''\n",
    "    gprinted = ''\n",
    "    sentence = seed\n",
    "    generated += sentence\n",
    "\n",
    "    nlines = 0\n",
    "    for i in range(1000):\n",
    "        x = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "        generated += next_char\n",
    "        gprinted += next_char\n",
    "\n",
    "        sentence = sentence[1:] + next_char\n",
    "        # Count the number of lines generated\n",
    "        if next_char == '\\n':\n",
    "            nlines += 1\n",
    "        if nlines > numlines:\n",
    "            break\n",
    "\n",
    "    if wseed:\n",
    "        gfile.write(seed + gprinted)\n",
    "    else:\n",
    "        gfile.write(gprinted)\n",
    "    gfile.write('\\n')\n",
    "    gfile.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[2048,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[Node: lstm_1/while/clip_by_value_1/Minimum = Minimum[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](lstm_1/while/add_3, lstm_1/while/Const_5)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'lstm_1/while/clip_by_value_1/Minimum', defined at:\n  File \"E:\\anaconda\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"E:\\anaconda\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"E:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"E:\\anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"E:\\anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"E:\\anaconda\\lib\\site-packages\\tornado\\ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"E:\\anaconda\\lib\\site-packages\\tornado\\ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"E:\\anaconda\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"E:\\anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"E:\\anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"E:\\anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"E:\\anaconda\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"E:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"E:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"E:\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"E:\\anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"E:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"E:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"E:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-022c9d66005b>\", line 14, in <module>\n    RNN(lsize, input_shape=(maxlen, len(chars)), implementation=impl, recurrent_dropout=dropout, return_sequences=True))\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\engine\\sequential.py\", line 165, in add\n    layer(x)\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\layers\\recurrent.py\", line 532, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\layers\\recurrent.py\", line 2194, in call\n    initial_state=initial_state)\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\layers\\recurrent.py\", line 649, in call\n    input_length=timesteps)\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3011, in rnn\n    maximum_iterations=input_length)\n  File \"E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3096, in while_loop\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2874, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2814, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3075, in <lambda>\n    body = lambda i, lv: (i + 1, orig_body(*lv))\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2996, in _step\n    tuple(constants))\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\layers\\recurrent.py\", line 640, in step\n    return self.cell.call(inputs, states, **kwargs)\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\layers\\recurrent.py\", line 1996, in call\n    f = self.recurrent_activation(z1)\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\activations.py\", line 160, in hard_sigmoid\n    return K.hard_sigmoid(x)\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3410, in hard_sigmoid\n    x = tf.clip_by_value(x, zero, one)\n  File \"E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\clip_ops.py\", line 64, in clip_by_value\n    t_min = math_ops.minimum(t, clip_value_max)\n  File \"E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 3014, in minimum\n    \"Minimum\", x=x, y=y, name=name)\n  File \"E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2048,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[Node: lstm_1/while/clip_by_value_1/Minimum = Minimum[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](lstm_1/while/add_3, lstm_1/while/Const_5)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2048,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[Node: lstm_1/while/clip_by_value_1/Minimum = Minimum[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](lstm_1/while/add_3, lstm_1/while/Const_5)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-dcf9968782cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbsize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch_it\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m               verbose=1)\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2719\u001b[0m                     \u001b[1;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[1;32m-> 2721\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2693\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2694\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2048,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[Node: lstm_1/while/clip_by_value_1/Minimum = Minimum[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](lstm_1/while/add_3, lstm_1/while/Const_5)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'lstm_1/while/clip_by_value_1/Minimum', defined at:\n  File \"E:\\anaconda\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"E:\\anaconda\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"E:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"E:\\anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"E:\\anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"E:\\anaconda\\lib\\site-packages\\tornado\\ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"E:\\anaconda\\lib\\site-packages\\tornado\\ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"E:\\anaconda\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"E:\\anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"E:\\anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"E:\\anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"E:\\anaconda\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"E:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"E:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"E:\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"E:\\anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"E:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"E:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"E:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-022c9d66005b>\", line 14, in <module>\n    RNN(lsize, input_shape=(maxlen, len(chars)), implementation=impl, recurrent_dropout=dropout, return_sequences=True))\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\engine\\sequential.py\", line 165, in add\n    layer(x)\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\layers\\recurrent.py\", line 532, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\layers\\recurrent.py\", line 2194, in call\n    initial_state=initial_state)\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\layers\\recurrent.py\", line 649, in call\n    input_length=timesteps)\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3011, in rnn\n    maximum_iterations=input_length)\n  File \"E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3096, in while_loop\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2874, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2814, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3075, in <lambda>\n    body = lambda i, lv: (i + 1, orig_body(*lv))\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2996, in _step\n    tuple(constants))\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\layers\\recurrent.py\", line 640, in step\n    return self.cell.call(inputs, states, **kwargs)\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\layers\\recurrent.py\", line 1996, in call\n    f = self.recurrent_activation(z1)\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\activations.py\", line 160, in hard_sigmoid\n    return K.hard_sigmoid(x)\n  File \"E:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3410, in hard_sigmoid\n    x = tf.clip_by_value(x, zero, one)\n  File \"E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\clip_ops.py\", line 64, in clip_by_value\n    t_min = math_ops.minimum(t, clip_value_max)\n  File \"E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 3014, in minimum\n    \"Minimum\", x=x, y=y, name=name)\n  File \"E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2048,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[Node: lstm_1/while/clip_by_value_1/Minimum = Minimum[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](lstm_1/while/add_3, lstm_1/while/Const_5)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "# train the model, output generated text after each iteration\n",
    "for iteration in range(iterations):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration %d' %((iteration + 1)))\n",
    "    model.fit(X, y,\n",
    "              batch_size=bsize,\n",
    "              epochs=epoch_it,\n",
    "              verbose=1)\n",
    "\n",
    "    gfile.write('-' * 50)\n",
    "    gfile.write('\\n')\n",
    "    gfile.write('Iteration %d n' % (iteration + 1))\n",
    "    seed = random_seed(chars, maxlen)\n",
    "    for diversity in [0.2, 0.4, 0.8, 1.0]:\n",
    "        gfile.write('\\n\\n')\n",
    "        gfile.write('DIV = %3.2f\\n\\n' % diversity)\n",
    "        generate_text(seed, numlines=10, gfile=gfile, wseed=False)\n",
    "        model.save(f\"./textgen-T4-N{lsize}-L{nlayers}-D{dropout}-{time.strftime('%Y%m%d%H%M%S')}.h5\")\n",
    "gfile.close()\n",
    "model.save(f\"./textgen-T4-N{lsize}-L{nlayers}-D{dropout}-{time.strftime('%Y%m%d%H%M%S')}.h5\")\n",
    "print()\n",
    "print(\"Ending\")\n",
    "\n",
    "# Note: If there is a ERROR of OOM(out of memory), you should use a more powerful machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

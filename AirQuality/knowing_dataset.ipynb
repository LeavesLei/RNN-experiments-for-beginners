{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numpy.lib.npyio.NpzFile at 0x1f413ee4f98>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dataset = np.load('./LondonAQ.npz')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GEltham', 'GWesthorne', 'BSladeGreen', 'GWoolwich']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = dataset.files\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43848, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[ls[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.4,  0. ,  5.7, 54.4,  2.8,  1. ,  1. ,  6. ,  0. ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[ls[0]][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert dataset to input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [0, 1, 2, 3, 4]\n",
    "airq = {}\n",
    "for d in ls:\n",
    "        airq[d] = dataset[d]\n",
    "        if vars is not None:\n",
    "            airq[d] = airq[d][:, vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43848, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = airq[ls[0]][:, 0].reshape(-1, 1)  ## We only use the first one feature from 9 features here.\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasize = 35064\n",
    "testsize = 8784\n",
    "lag = 6\n",
    "ahead = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35064, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_train = data[:datasize, :]\n",
    "wind_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing below codes and trying to print train[0], train[1] and train[2]. Finding something from them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35058, 7, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ahead = 1 - 1\n",
    "lvect = []\n",
    "for i in range(lag):\n",
    "    lvect.append(wind_train[i: -lag - ahead + i])\n",
    "lvect.append(wind_train[lag + ahead:])\n",
    "train = np.stack(lvect, axis=1)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train[:, :lag], train[:, -1:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_test = data[datasize:datasize + testsize, 0].reshape(-1, 1)\n",
    "lvect = []\n",
    "for i in range(lag):\n",
    "    lvect.append(wind_test[i: -lag - ahead + i])\n",
    "lvect.append(wind_test[lag + ahead:])\n",
    "test = np.stack(lvect, axis=1)\n",
    "test_x, test_y = test[:, :lag], test[:, -1:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we get the data for our RNN: train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def architecture(neurons, drop, nlayers, activation, activation_r, rnntype, impl=1):\n",
    "    \"\"\"\n",
    "    RNN architecture\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    RNN = LSTM if rnntype == 'LSTM' else GRU\n",
    "    model = Sequential()\n",
    "    if nlayers == 1:\n",
    "        model.add(RNN(neurons, input_shape=(train_x.shape[1], train_x.shape[2]), implementation=impl,\n",
    "                      recurrent_dropout=drop, activation=activation, recurrent_activation=activation_r))\n",
    "    else:\n",
    "        model.add(RNN(neurons, input_shape=(train_x.shape[1], train_x.shape[2]), implementation=impl,\n",
    "                      recurrent_dropout=drop, activation=activation, recurrent_activation=activation_r,\n",
    "                      return_sequences=True))\n",
    "        for i in range(1, nlayers - 1):\n",
    "            model.add(RNN(neurons, recurrent_dropout=drop, implementation=impl,\n",
    "                          activation=activation, recurrent_activation=activation_r, return_sequences=True))\n",
    "        model.add(RNN(neurons, recurrent_dropout=drop, activation=activation,\n",
    "                      recurrent_activation=activation_r, implementation=impl))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load information from config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_config_file(nfile, abspath=False):\n",
    "    \"\"\"\n",
    "    Read the configuration from a json file\n",
    "\n",
    "    :param abspath:\n",
    "    :param nfile:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    ext = '.json' if 'json' not in nfile else ''\n",
    "    pre = '' if abspath else './'\n",
    "    fp = open(pre + nfile + ext, 'r')\n",
    "\n",
    "    s = ''\n",
    "\n",
    "    for l in fp:\n",
    "        s += l\n",
    "\n",
    "    return json.loads(s)\n",
    "\n",
    "config = load_config_file('config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, GRU\n",
    "\n",
    "impl = 2\n",
    "model = architecture(neurons=config['arch']['neurons'],\n",
    "                         drop=config['arch']['drop'],\n",
    "                         nlayers=config['arch']['nlayers'],\n",
    "                         activation=config['arch']['activation'],\n",
    "                         activation_r=config['arch']['activation_r'], rnntype=config['arch']['rnn'], impl=impl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = config['training']['optimizer']\n",
    "\n",
    "if optimizer == 'rmsprop':\n",
    "    if 'lrate' in config['training']:\n",
    "        optimizer = RMSprop(lr=config['training']['lrate'])\n",
    "    else:\n",
    "        optimizer = RMSprop(lr=0.001)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4294b1ba8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbacks = []\n",
    "model.fit(train_x, train_y, batch_size=config['training']['batch'],\n",
    "          epochs=config['training']['epochs'],\n",
    "          validation_data=(test_x, test_y),\n",
    "          verbose=False, callbacks=cbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
